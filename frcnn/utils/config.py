import json
from keras import backend as K


class Config:

    def __init__(self):
        # load config_tmp config file
        self.config_tmp = json.load(open('./config.json', 'r'))
        
        # verbose
        self.verbose = bool(self.config_tmp['verbose'])

        # base CNN model
        self.conv_net = self.config_tmp['conv_net']

        # setting for data augmentation
        self.horizontal_flips = bool(self.config_tmp['horizontal_flips'])
        self.vertical_flips = bool(self.config_tmp['vertical_flips'])
        self.rotate_90 = bool(self.config_tmp['rotate_90'])

        # anchor box scales
        self.anchor_scales = self.config_tmp['anchor_scales']

        # anchor box ratios
        self.anchor_ratios = self.config_tmp['anchor_ratios']

        # size to resize the smallest side of the image
        self.img_small_size = self.config_tmp['img_small_size']

        # image channel-wise mean to subtract
        self.img_channel_mean = self.config_tmp['img_channel_mean']
        self.img_scaling_factor = self.config_tmp['img_scale_factor']

        # number of ROIs at once
        self.num_roi = self.config_tmp['num_roi']

        # stride at the RPN (this depends on the network configuration)
        self.stride = self.config_tmp['stride']
        
        # to handle class imbalance
        self.balanced_classes = bool(self.config_tmp['balanced_classes'])

        # scaling the stdev
        self.std_scaling = self.config_tmp['std_scaling']
        self.class_regress_std = self.config_tmp['class_regress_std']

        # overlaps for RPN
        self.rpn_min_overlap = self.config_tmp['rpn_min_overlap']
        self.rpn_max_overlap = self.config_tmp['rpn_max_overlap']

        # overlaps for classifier ROIs
        self.classifier_min_overlap = self.config_tmp['classifier_min_overlap']
        self.classifier_max_overlap = self.config_tmp['classifier_max_overlap']

        # placeholder for the class mapping, automatically generated by the parser
        self.class_mapping = None
        
        # training epochs
        self.epochs = self.config_tmp['epochs']
        self.epoch_length = self.config_tmp['epoch_length']

        # inference confidence
        self.bbox_threshold = self.config_tmp['bbox_threshold']

        #location of pretrained weights for the base network
        # weight files can be found at:
        # https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5
        # https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5

        GPU = bool(self.config_tmp['use_GPU'])

        self.model_path = './weights/model_frcnn_voc+coco.%s.hdf5' % self.conv_net
        self.train_path_voc = self.config_tmp['train_path_voc']
        self.train_path_coco = self.config_tmp['train_path_coco']
        self.log_path = './log'